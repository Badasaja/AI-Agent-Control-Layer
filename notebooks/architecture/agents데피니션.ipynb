{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acf2f6e6",
   "metadata": {},
   "source": [
    "### 워크플로우 이니시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2712620d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:26:49 - core.logging_utils - INFO - Logging initialized - logs directory: c:\\Users\\kakao\\Desktop\\AI_Agent\\Semantic Layer\\logs\n",
      "16:26:49 - core.logging_utils - INFO - Log rotation configured: max 10.0MB per file, keeping 5 backups\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "from pathlib import Path\n",
    "from typing import List, Dict\n",
    "from datetime import datetime\n",
    "\n",
    "from entity.process import GuardCondition, TaskSpec, TaskType, Layer, AgentNature, AgentRole, Process\n",
    "from entity.validators import TokenValidator, SpecChainValidator\n",
    "from entity.tokens import Token\n",
    "from core.utils import load_resource_specs\n",
    "from core.tokenDB import TokenRepository\n",
    "import os\n",
    "import logging\n",
    "from core import logging_utils\n",
    "from pathlib import Path\n",
    "from core.tokenDB import TokenRepository\n",
    "from core.utils import load_cfg\n",
    "\n",
    "# 0. master config 불러오기\n",
    "cfg = load_cfg(Path().parent.parent / \"cfg\" / \"prod.yaml\")\n",
    "log_levels = {\n",
    "    \"DEBUG\": logging.DEBUG,\n",
    "    \"INFO\": logging.INFO,\n",
    "    \"WARNING\": logging.WARNING,\n",
    "    \"ERROR\": logging.ERROR,\n",
    "    \"CRITICAL\": logging.CRITICAL\n",
    "}\n",
    "\n",
    "log_level = log_levels.get(os.environ.get(\"LOG_LEVEL\", \"INFO\").upper(), logging.INFO)\n",
    "\n",
    "logging_utils.setup_logging(\n",
    "    log_dir=\"logs\",\n",
    "    log_level=log_level,\n",
    "    max_bytes=10 * 1024 * 1024, \n",
    "    backup_count=5, \n",
    "    console_output=True \n",
    ")\n",
    "\n",
    "logging_utils.cleanup_old_logs(log_dir=\"logs\", days_to_keep=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb4fc57",
   "metadata": {},
   "source": [
    "### entity/prompts.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3be9b9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from entity import prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4929ee3",
   "metadata": {},
   "source": [
    "### LLM Invoke 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e96c0cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:26:58 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Don't make it bad \n",
      "Take a sad song and make it better \n",
      "Remember to let her into your heart \n",
      "Then you can start to make it better \n",
      "\n",
      "Hey Jude, don't be afraid \n",
      "You were made to go out and get her \n",
      "The minute you let her under your skin \n",
      "Then you begin to make it better \n",
      "\n",
      "And anytime you feel the pain, hey Jude\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm_client = init_chat_model(model = \"gpt-3.5-turbo\", model_provider=\"openai\")\n",
    "print(getattr(llm_client.invoke(\"hey jude\"), 'content'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d5738c",
   "metadata": {},
   "source": [
    "### DB 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66a745e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. master config 불러오기\n",
    "cfg = load_cfg(Path().parent.parent / \"cfg\" / \"prod.yaml\")\n",
    "\n",
    "# 1. repo 불러오기\n",
    "repo = TokenRepository(cfg['location']['token_db'], table_name=\"SOHO_LOAN_raw_knowledge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3dd1eed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[Token: TKN_금융연수원_소호 여신심사_0000]\n",
       " ├─ Timestamp: 2026-02-03 14:24:23.807\n",
       " └─ Content  : # 소호\n",
       "# 여신심사\n",
       "SOHO CREDIT MANAGEMENT\n",
       "\n",
       "백운수 저\n",
       "\n",
       "![표지 그림: 건물 위에서 사람들이 동전(₩)을 옮기거나 망원경을 보는 일러스트]\n",
       "\n",
       "**한국금융연수원**\n",
       "KOREA BANKING INSTITUTE\n",
       "\n",
       "\n",
       "\n",
       "---\n",
       "\n",
       "(빈 페이지)\n",
       "\n",
       "\n",
       "\n",
       "---\n",
       "\n",
       "# 머리말\n",
       "\n",
       "필자가 한국금융연수원에서 수년간 기업신용분석과 여신심사사례를 강의해 오면서 여러 수강자님으로부터 건의를 받은 내용이 바로 소기업과 소상공인에 관한 평가방법을 소개하여 달라는 주문이었습니다. 대기업들은 대부분 상장기업으로서 외부 전문신용평가회사의 신용등급이 공시되고 있을 뿐만 아니라 그들은 필요한 자금수요를 주로 회사채 발행이나 유상증자 등 직접금융에 의존하고 있는 추세이기 때문에 국내 금융기관들은 여신의 운용이 더욱 어려워져 중소기업이나 소호 대출 또는 순수 개인들에 대한 모기지론에 집중하고 있는 현실을 볼 때 수강자님들의 이와 같은 건의가 의미 있는 주문이라고 생각하였습니다.\n",
       "\n",
       "이러한 요청과 국내 여신시..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo.load(table_name_load=\"SOHO_LOAN_raw_knowledge\", trace_id = \"TKN_금융연수원_소호 여신심사_0000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24b31e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "from typing import Dict, Any, List, Optional\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# (가정) 앞서 만든 TokenRepository, Token 클래스 import\n",
    "# from db_manager import TokenRepository\n",
    "# from token_schema import Token\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, llm, db_repo):\n",
    "        \"\"\"\n",
    "        self.llm = llm 인스턴스\n",
    "        self.repo = Agent의 지식 베이스\n",
    "        \"\"\"\n",
    "        self.llm = llm\n",
    "        self.repo = db_repo\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        self.logger.info(\"TokenAnalysisAgent initialized.\")\n",
    "\n",
    "    def run(self, state: Dict[str, Any], config: RunnableConfig) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        [Logic]\n",
    "        1. State에서 타겟 토큰 추출\n",
    "        2. DB에서 연관된 Reference Token 조회 (Context)\n",
    "        3. LLM Invoke (Prompt = Context + Target)\n",
    "        4. 결과 파싱 및 State 업데이트\n",
    "        \"\"\"\n",
    "        \n",
    "        # 1. Extract Target Token from State\n",
    "        # (State에 현재 처리 중인 토큰이 'current_token' 키로 있다고 가정)\n",
    "        current_token_data = state.get(\"current_token\")\n",
    "        if not current_token_data:\n",
    "            self.logger.warning(\"No token found in state to analyze.\")\n",
    "            return {}\n",
    "\n",
    "        # Pydantic 모델로 변환 (편의상 딕셔너리 그대로 사용도 가능하나, 메서드 활용 위해 변환 권장)\n",
    "        # target_token = Token(**current_token_data) \n",
    "        target_token = current_token_data # 여기선 Dict로 가정하고 진행\n",
    "\n",
    "        # 2. agent role / type 추출\n",
    "        agent_role = state.get(\"agent_role\", None)\n",
    "        agent_nature = state.get(\"agent_nature\", None)\n",
    "        \n",
    "        # 2. [Routing] AgentRole 별 프롬프트 결정\n",
    "        # LLM 타입인 경우에만 prompts.py의 베이스 프롬프트 주입\n",
    "        final_system_prompt = task_config.get(\"system_prompt\", \"You are an analyst.\")\n",
    "        \n",
    "        if agent_nature == \"LLM\":\n",
    "            role_base = self._get_role_base_prompt(agent_role)\n",
    "            # 베이스 페르소나 + 태스크 고유 지침 결합\n",
    "            final_system_prompt = f\"{role_base}\\n\\n[Task Instruction]\\n{final_system_prompt}\"\n",
    "        \n",
    "        # Task Config 추출 (프롬프트, 토픽 설정 등)\n",
    "        task_config = state.get(\"task_config\", {})        \n",
    "        retrieval_topics = task_config.get(\"retrieval_topics\", [])\n",
    "\n",
    "        # 2. Context Retrieval (Single DB Logic)\n",
    "        # 설정된 토픽이 없으면 타겟 토큰의 토픽을 그대로 사용\n",
    "        search_keys = retrieval_topics if retrieval_topics else list(target_token.get(\"topics\", {}).keys())\n",
    "        \n",
    "        try:\n",
    "            # repo.find_context_tokens는 List[Token] 객체를 반환한다고 가정\n",
    "            context_tokens = self.repo.find_context_tokens(search_keys, limit=5)\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Context retrieval failed: {e}\")\n",
    "            context_tokens = []\n",
    "\n",
    "        # 3. Build Prompt\n",
    "        context_str = self._format_context(context_tokens)\n",
    "        \n",
    "        full_prompt = f\"\"\"\n",
    "        {final_system_prompt}\n",
    "\n",
    "        [Reference Knowledge (Context)]\n",
    "        The following are related tokens retrieved from the internal database:\n",
    "        {context_str if context_tokens else \"No related context found.\"}\n",
    "\n",
    "        [Target Input (Token to Analyze)]\n",
    "        - Content: {json.dumps(target_token.get('content', {}), ensure_ascii=False)}\n",
    "        - Metadata: {target_token.get('topics', {})}\n",
    "\n",
    "        [Instruction]\n",
    "        Analyze the 'Target Input' based on the 'Reference Knowledge'.\n",
    "        Check for consistency, factual accuracy, and compliance.\n",
    "        \n",
    "        Output must be a valid JSON object with the following structure:\n",
    "        {{\n",
    "            \"analysis_summary\": \"...\",\n",
    "            \"risk_score\": 0.0 ~ 1.0,\n",
    "            \"is_compliant\": true/false,\n",
    "            \"reasoning\": \"...\"\n",
    "        }}\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            # 4. Invoke LLM\n",
    "            response = self.llm.invoke(full_prompt)\n",
    "            response_content = response.content if hasattr(response, 'content') else str(response)\n",
    "\n",
    "            # 5. Parse JSON\n",
    "            analysis_data = json.loads(response_content.strip())\n",
    "\n",
    "            # 6. Update Token Content (Evolution)\n",
    "            # 기존 콘텐츠에 분석 결과를 병합\n",
    "            updated_content = target_token.get('content', {}).copy()\n",
    "            updated_content.update({\n",
    "                \"analysis_result\": analysis_data,\n",
    "                \"referenced_ids\": [t.trace_id for t in context_tokens] # Lineage 추적용\n",
    "            })\n",
    "\n",
    "            # 7. Return Updated State\n",
    "            # State의 current_token을 업데이트된 내용으로 교체\n",
    "            updated_token = target_token.copy()\n",
    "            updated_token['content'] = updated_content\n",
    "            \n",
    "            # (로그 출력)\n",
    "            if analysis_data.get(\"is_compliant\"):\n",
    "                self.logger.info(f\"✅ Token {target_token.get('trace_id')} Analysis Passed.\")\n",
    "            else:\n",
    "                self.logger.warning(f\"⚠️ Token {target_token.get('trace_id')} Flagged: {analysis_data.get('reasoning')}\")\n",
    "\n",
    "            return {\n",
    "                \"current_token\": updated_token,\n",
    "                \"analysis_result\": analysis_data # 필요시 별도 키로도 반환\n",
    "            }\n",
    "\n",
    "        except json.JSONDecodeError as e:\n",
    "            self.logger.error(f\"Failed to parse analysis JSON: {e}\")\n",
    "            return {\"error\": \"JSON Parsing Failed\"}\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Token analysis execution failed: {e}\")\n",
    "            return {\"error\": str(e)}\n",
    "\n",
    "    def _format_context(self, tokens: List) -> str:\n",
    "        \"\"\"Helper to format reference tokens into string\"\"\"\n",
    "        formatted = \"\"\n",
    "        for t in tokens:\n",
    "            # t가 객체라면 t.content, 딕셔너리라면 t['content'] 처리 필요\n",
    "            # 여기선 객체(Pydantic)라고 가정\n",
    "            t_id = getattr(t, 'trace_id', 'Unknown')\n",
    "            t_content = getattr(t, 'content', {})\n",
    "            t_topics = getattr(t, 'topics', {})\n",
    "            \n",
    "            formatted += f\"\"\"\n",
    "            ---\n",
    "            [Ref Token ID: {t_id}]\n",
    "            Topics: {t_topics}\n",
    "            Content Summary: {str(t_content)[:300]}...\n",
    "            \"\"\"\n",
    "        return formatted\n",
    "    \n",
    "    def _get_role_base_prompt(self, role: str) -> str:\n",
    "        \"\"\"Role에 따른 프롬프트 매핑 (Internal Helper)\"\"\"\n",
    "        mapping = {\n",
    "            \"SUPERVISOR\": prompts.SUPERVISOR_PROMPT,\n",
    "            \"CONSULTANT\": prompts.CONSULTANT_PROMPT,\n",
    "            \"WORKER\": prompts.WORKER_PROMPT\n",
    "        }\n",
    "        return mapping.get(role, prompts.DEFAULT_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9f3e00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c6c2a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "53bd3964",
   "metadata": {},
   "source": [
    "### entity/agents.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62566fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95da5f93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
